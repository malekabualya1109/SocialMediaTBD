{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4e51640-b956-4937-af66-3fd0dccf3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3ee2a3f-6243-4c08-9e95-63438e24d8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5392 entries, 0 to 5391\n",
      "Columns: 110 entries, id to in_youtubers\n",
      "dtypes: float64(2), int64(104), object(4)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#loading the data set\n",
    "try:\n",
    "    df = pd.read_csv(\"talent.csv\")\n",
    "except Exception as e:\n",
    "    print(\"Error reading CSV file:\", e)\n",
    "    sys.exit(1)\n",
    "\n",
    "df.info()\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0d68629-11f6-4852-b67e-ca5db829e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binary_cols = [col for col in df.columns if col.startswith(\"in_\")]\n",
    "df[binary_cols] = df[binary_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "df['name'] = df['name'].astype(str).str.strip()\n",
    "\n",
    "# handling duplicates\n",
    "duplicates = df[df['name'].duplicated(keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Warning: Duplicate names found:\")\n",
    "    print(duplicates[['name']])\n",
    "    df = df.drop_duplicates(subset='name', keep='first')\n",
    "    print(\"Dropped duplicates, keeping first occurrence.\")\n",
    "\n",
    "# checking non-binary values\n",
    "non_binary = [col for col in binary_cols if not df[col].isin([0, 1, np.nan]).all()]\n",
    "if non_binary:\n",
    "    print(\"Warning: Non-binary values found in columns:\", non_binary)\n",
    "\n",
    "# Check sparsity and category distribution\n",
    "sparsity = (df[binary_cols] == 0).mean().mean()\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d795b363-df6f-4226-96e0-c904bdff73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new DataFrame X that includes the 'stars' column (a quality score)\n",
    "# along with a set of binary columns (e.g., features that are either True/False)\n",
    "X = df[['stars'] + binary_cols].copy()\n",
    "\n",
    "# Normalize the 'stars' column:\n",
    "# Subtract the mean and divide by the standard deviation.\n",
    "# We add a small number (1e-6) to the standard deviation so we never divide by zero.\n",
    "X['stars'] = (X['stars'] - X['stars'].mean()) / (X['stars'].std() + 1e-6)\n",
    "\n",
    "# Calculate moderate weights for the binary columns:\n",
    "# 1. For each binary column, sum its values (to see how common each feature is).\n",
    "# 2. Take the reciprocal (1/count) so that features appearing rarely get higher weight.\n",
    "# 3. Use np.log1p to apply a logarithm that smooths out the weights.\n",
    "# 4. Clip the weights between 0 and 10 to avoid extreme values.\n",
    "weights = np.log1p(1 / (df[binary_cols].sum() + 1e-6)).clip(0, 10)\n",
    "\n",
    "# Add a default weight of 1 for the 'stars' column.\n",
    "# We combine this with the previously calculated weights for the binary columns.\n",
    "weights = pd.concat([pd.Series(1.0, index=['stars']), weights])\n",
    "\n",
    "# Multiply each column in our feature matrix X by its corresponding weight.\n",
    "# This creates a weighted feature matrix where more important features have a bigger effect.\n",
    "X_weighted = X.mul(weights)\n",
    "\n",
    "# Compute the cosine similarity between every pair of rows in the weighted feature matrix.\n",
    "# The result is a similarity matrix indicating how similar each pair is.\n",
    "similarity_matrix = cosine_similarity(X_weighted)\n",
    "\n",
    "# Make sure all similarity values are in the range [0, 1].\n",
    "# This might be needed in case some small numerical issues cause values to slightly exceed these boundaries.\n",
    "similarity_matrix = np.clip(similarity_matrix, 0, 1)\n",
    "\n",
    "# Convert the similarity matrix (a NumPy array) back into a DataFrame.\n",
    "# Use the names from df['name'] as both the row and column labels.\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=df['name'], columns=df['name'])\n",
    "\n",
    "# Check if any names from the original data are missing in the similarity DataFrame.\n",
    "missing = set(df['name']) - set(similarity_df.index)\n",
    "if missing:\n",
    "    # If names are missing, print a warning message.\n",
    "    print(f\"Warning: Missing names in similarity_df: {missing}\")\n",
    "\n",
    "# Ensure that all printed output is sent to the command prompt immediately.\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b19e82c-9e32-4b95-85f3-7ff3ea28604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4. Define Recommendation Functions\n",
    "# -------------------------\n",
    "def recommend_similar_items(item_name, sim_df, df, binary_cols, top_n=5):\n",
    "    if item_name not in sim_df.index:\n",
    "        raise KeyError(f\"'{item_name}' not in similarity DataFrame index. Try: {list(sim_df.index[:5])}\")\n",
    "    sim_scores = sim_df.loc[item_name]\n",
    "    if isinstance(sim_scores, pd.DataFrame):\n",
    "        print(f\"Warning: Multiple entries for '{item_name}'. Using first row.\")\n",
    "        sim_scores = sim_scores.iloc[0]\n",
    "    sim_scores = sim_scores.drop(item_name, errors='ignore')\n",
    "    top_items = sim_scores.sort_values(ascending=False).head(top_n)\n",
    "    # NEW: Fallback to popular items if all zeros\n",
    "    if top_items.max() < 1e-6:\n",
    "        top_items = df.nlargest(top_n, 'stars')['name']\n",
    "        top_items = pd.Series([0.0] * top_n, index=top_items)\n",
    "    return top_items\n",
    "\n",
    "\n",
    "def recommend_for_user(user_interests, X, item_names, df, top_n=5):\n",
    "    invalid_interests = [i for i in user_interests if i not in X.columns]\n",
    "    if invalid_interests:\n",
    "        print(f\"Warning: Invalid interests {invalid_interests}. Ignoring.\")\n",
    "        user_interests = [i for i in user_interests if i in X.columns]\n",
    "    if not user_interests:\n",
    "        print(\"No valid interests. Returning popular items.\")\n",
    "        return df.nlargest(top_n, 'stars')['name'].to_series()\n",
    "    user_vector = np.array([1 if col in user_interests else 0 for col in X.columns])\n",
    "    sim_scores = cosine_similarity(X, [user_vector]).flatten()\n",
    "    sim_series = pd.Series(sim_scores, index=item_names)\n",
    "    # NEW: Handle NaN and boost multi-interest matches\n",
    "    sim_series = sim_series.fillna(0)\n",
    "    interest_counts = df[user_interests].sum(axis=1)\n",
    "    sim_series = sim_series * (1 + 0.1 * interest_counts)\n",
    "    top_items = sim_series.sort_values(ascending=False).head(top_n)\n",
    "    if top_items.max() < 1e-6:\n",
    "        print(\"No matching items. Returning popular items.\")\n",
    "        top_items = df.nlargest(top_n, 'stars')['name'].to_series()\n",
    "    return top_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7271809a-4b73-4058-beac-f10ca294bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 5. Evaluation Functions\n",
    "# -------------------------\n",
    "def precision_at_k(item_name, sim_df, true_df, binary_cols, k=5):\n",
    "    try:\n",
    "        recs = recommend_similar_items(item_name, sim_df, true_df, binary_cols, k)\n",
    "        true_cats = set(true_df[true_df['name'] == item_name][binary_cols].columns[\n",
    "            true_df[true_df['name'] == item_name][binary_cols].iloc[0] == 1])\n",
    "        if not true_cats:\n",
    "            return 0\n",
    "        relevant_count = 0\n",
    "        for rec_name in recs.index:\n",
    "            rec_cats = set(true_df[true_df['name'] == rec_name][binary_cols].columns[\n",
    "                true_df[true_df['name'] == rec_name][binary_cols].iloc[0] == 1])\n",
    "            if true_cats.intersection(rec_cats):\n",
    "                relevant_count += 1\n",
    "        return relevant_count / k\n",
    "    except KeyError:\n",
    "        return 0\n",
    "        \n",
    "def compute_coverage(sim_df, df, binary_cols, top_n=5):\n",
    "    all_recs = set()\n",
    "    for name in df['name']:\n",
    "        try:\n",
    "            recs = recommend_similar_items(name, sim_df, df, binary_cols, top_n)\n",
    "            all_recs.update(recs.index)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return len(all_recs) / len(df) if len(df) > 0 else 0\n",
    "\n",
    "def intra_list_similarity(rec_names, sim_df):\n",
    "    if len(rec_names) < 2:\n",
    "        return 0\n",
    "    sim_scores = [sim_df.loc[n1, n2] for i, n1 in enumerate(rec_names) \n",
    "                  for n2 in rec_names[i+1:]]\n",
    "    return np.mean(sim_scores) if sim_scores else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3af44719-1898-455a-b569-a5c532bc3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for 'Perez Hilton':\n",
      "name\n",
      "Kristen Ledlow     0.999996\n",
      "Darren Rovell      0.999994\n",
      "Matt Hasselbeck    0.999984\n",
      "Bob Menery         0.999978\n",
      "Brian Balthazar    0.999957\n",
      "Name: Perez Hilton, dtype: float64\n",
      "Categories of recommended items:\n",
      "in_commentators     5\n",
      "in_featured         4\n",
      "in_athletes         1\n",
      "in_comedians        1\n",
      "in_football         1\n",
      "in_reality_tv       1\n",
      "in_90_day_fiance    0\n",
      "in_artists          0\n",
      "in_animals          0\n",
      "in_american_idol    0\n",
      "dtype: int64\n",
      "Intra-list diversity: 0.000\n",
      "\n",
      "Recommendations for interests ['in_90_day_fiance', 'in_artists']:\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "dtype: float64\n",
      "Interest flags for recommended items:\n",
      "Empty DataFrame\n",
      "Columns: [in_90_day_fiance, in_artists]\n",
      "Index: []\n",
      "\n",
      "Items with both ['in_90_day_fiance', 'in_artists']: 0\n",
      "\n",
      "Average Precision@5: 0.999\n",
      "Coverage: 0.681\n",
      "Average stars of recommendations: nan (dataset avg: 3.69)\n",
      "Average reactions of recommendations: nan (dataset avg: 10.07)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 6. Example Usage and Evaluation\n",
    "# -------------------------\n",
    "# Select valid item (NEW: From df['name'])\n",
    "item_of_interest = df['name'].iloc[0]  # First valid name\n",
    "try:\n",
    "    recs = recommend_similar_items(item_of_interest, similarity_df, df, binary_cols, top_n=5)\n",
    "    print(f\"\\nRecommendations for '{item_of_interest}':\")\n",
    "    print(recs)\n",
    "    print(\"Categories of recommended items:\")\n",
    "    print(df[df['name'].isin(recs.index)][binary_cols].sum().sort_values(ascending=False).head(10))\n",
    "    diversity = 1 - intra_list_similarity(recs.index, similarity_df)\n",
    "    print(f\"Intra-list diversity: {diversity:.3f}\")\n",
    "except KeyError as e:\n",
    "    print(\"KeyError:\", e)\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "user_interests = [\"in_90_day_fiance\", \"in_artists\"]\n",
    "try:\n",
    "    user_recs = recommend_for_user(user_interests, X, df['name'], df, top_n=5)\n",
    "    print(f\"\\nRecommendations for interests {user_interests}:\")\n",
    "    print(user_recs)\n",
    "    print(\"Interest flags for recommended items:\")\n",
    "    print(df[df['name'].isin(user_recs.index)][user_interests])\n",
    "except Exception as e:\n",
    "    print(\"Error in user recommendations:\", e)\n",
    "\n",
    "\n",
    "both_interests = df[df[user_interests].eq(1).all(axis=1)]['name']\n",
    "print(f\"\\nItems with both {user_interests}: {len(both_interests)}\")\n",
    "if not both_interests.empty:\n",
    "    print(both_interests.head())\n",
    "\n",
    "# Use full similarity_df for evaluation (NEW: Avoid train/test issues)\n",
    "precision_scores = []\n",
    "for name in df['name'].sample(frac=0.2, random_state=42):  # Subsample for speed\n",
    "    precision = precision_at_k(name, similarity_df, df, binary_cols, k=5)\n",
    "    if precision is not None:\n",
    "        precision_scores.append(precision)\n",
    "avg_precision = np.mean(precision_scores) if precision_scores else 0\n",
    "print(f\"\\nAverage Precision@5: {avg_precision:.3f}\")\n",
    "\n",
    "coverage = compute_coverage(similarity_df, df, binary_cols, top_n=5)\n",
    "print(f\"Coverage: {coverage:.3f}\")\n",
    "\n",
    "if 'stars' in df.columns and 'reactions' in df.columns:\n",
    "    try:\n",
    "        rec_names = user_recs.index\n",
    "        avg_stars = df[df['name'].isin(rec_names)]['stars'].mean()\n",
    "        avg_reactions = df[df['name'].isin(rec_names)]['reactions'].mean()\n",
    "        dataset_stars = df['stars'].mean()\n",
    "        dataset_reactions = df['reactions'].mean()\n",
    "        print(f\"Average stars of recommendations: {avg_stars:.2f} (dataset avg: {dataset_stars:.2f})\")\n",
    "        print(f\"Average reactions of recommendations: {avg_reactions:.2f} (dataset avg: {dataset_reactions:.2f})\")\n",
    "    except:\n",
    "        print(\"Error computing stars/reactions\")\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac426f67-96ec-41e9-960e-add1d77d6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_columns = [col for col in talent.columns if col.startswith(\"in_\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b96696b8-9d90-4594-a1de-2d0aca1cfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure they are numeric (e.g., 0 or 1)\n",
    "talent[da_columns] = talent[da_columns].apply(pd.to_numeric, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f542ab0-63ee-495b-856c-dcf0999e5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = talent[da_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c3c5e0f-1ba8-4d63-b2bc-c93475c71311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2f92c-1eb4-4896-9cbf-8cc041bf6ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
